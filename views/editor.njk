---
layout: note.njk
title: Editing
---


<editor-hf>
  <h1>Title title title <em>And now, a word from our sponsor</em></h1><p>
       &nbsp;
  </p><p>
&nbsp;
  </p><p>

      
  </p>
  <p></p>
  <p>Uselessly  spaced    out

    maybe even &nbsp; like this
  </p>
  <p>Hi. Here is some <strong>Bold text! </strong><strong><em>Bold and italicized!</em> bold </strong>
    <strong>back to bold...</strong>
  </p>
  <h2>section</h2>
  <p>blessed are these &lt;p&gt;</p>
  <p>Hey! edge case <span> more like‚Äîedge SPACE</span></p>
  <p><span>want to see even edgier space? </span><span> yeah you do you-</span></p>
  <p><span>WATCH OUT CURVE</span><span> ball</span></p>
  <p><span>egads.</span>   <span>ball</span></p>
  <p>Seems we've &nbsp;&nbsp;  &nbsp; no choice</p>
  <h2>second section</h2>
  <p>A serious paragraph</p>
  <p>A trial of inline <span>&nbsp;</span></p>
  <p>Space after </p>
  <p>
    A long bit of text. 
    
    See, it's rather unfortunate that we don't write like this
    often. The DOM will take this chunk of text. I think it should keep it within
    the same paragraph. Sometimes it will rearrange HTML for you. It is rather
    forgiving of the input it accepts, such as mixing tags that would normally
    be separated into different elements.

  </p>
  <!-- <pre> -->
    <!-- mehumbra     5 -->
    <!-- <em>bla   h!</em> -->
  <!-- </pre> -->
  <p>
    I could (and probably should) nest my header tags. Accessibility wise I think it
    reads the same as the "flattened" kind where all these elements are next to each
    other. My document model might produce html that's nested which will be useful
    for querying the headers when I eventually make my list element.
  </p>
  <h2>Conclusion</h2>
  <p>
    Hello, üåê!
  </p>
  <p>
    Here our sample text adventure comes to an end. I haven't decided whether I want to
    permit the natural edit events from <span>contentEditable</span> to take their
    natural course or if I'd prefer to interrupt each event and re-render each time. It
    is easy to let the browser do the work but I'll have to take interrupts regardless.
    I want to identify what I'd need to supplement with code.
  </p>
</editor-hf>

<div id="toolmark">
  <p>
    toolmark
  </p>
</div>

<!-- Even HTML breaks it down to separate blocks. Which means we can probably leave it
in the editor, though I'd prefer to.. do better I suppose.
Am I building out a full AST?
 -->

<!-- <script type="module" src="js/modules/document/DOM.mjs"></script> -->
<script>
  let hf = document.querySelector('editor-hf')

  let testElem = hf.children[11]

  let toolmark = document.querySelector("#toolmark")

  function label(fragments, ...values) {
    let result = ""
    for (let i = 0; i < values.length; i++) {
      result += `<strong>${fragments[i].trim()}:</strong>&nbsp;${values[i]}<br>`
    }
    return result
  }

  toolmark.children[0].innerHTML = label`Test ${"label"} the best guess is ${'not this one'}`

  function lazyEscape(string) {

  }

  // document.addEventListener('selectionchange', (sce) => console.debug(sce) )
  import("/js/modules/document/DOM.mjs").then( m=> {
    let { renderedText } = m
    document.addEventListener('selectionchange', (sce) => {
      const sel = window.getSelection()
      const re = sel.getRangeAt(0)  // Not handling multi ranges for now

      // let startOffset = textOffset(hf, re.startContainer).length + re.startOffset;
      // let endOffset = textOffset(hf, re.endContainer).length + re.endOffset;
      // let focusOffset = textOffset(hf, sel.focusNode).length + sel.focusOffset// - sel.focusNode.textContent.length;
      let startOffset = renderedText(hf, re.startContainer).length + re.startOffset - re.startContainer.textContent.length;
      let endOffset = renderedText(hf, re.endContainer).length + re.endOffset - re.endContainer.textContent.length;
      let focusOffset = renderedText(hf, sel.focusNode).length + sel.focusOffset - sel.focusNode.textContent.length;
      let charUnderCursor = hf.innerText.codePointAt(focusOffset)
      // let selectedText = [...hf.innerText].slice(startOffset, endOffset)
      // need to html escape
      let selectedText = hf.innerText.slice(startOffset, endOffset)
      if (selectedText.length == 0) {
        selectedText = charUnderCursor ? String.fromCodePoint(charUnderCursor) : '-'
      }

      // TODO get an html escaper for selectedText if we want to spit it out 'raw'. Maybe.. an "escape" component
      // TODO work out a way to handle ctrl-a. I think it 'selects' hf-editor which breaks the tree traversal (yields undefined)
      toolmark.querySelector('p').innerHTML = label`Offset ${focusOffset} Length ${endOffset - startOffset} Character ${selectedText}`

    })
  })

  // hf.addEventListener('click', (clickEvent) => {
  //   // console.log('Click:',clickEvent)
  //   let { clientX, clientY } = clickEvent
  //   console.log(document.caretPositionFromPoint(clientX, clientY))
  // })


  // what we might call 'breaking' white space
  // considered as *all* unicode whitespace
  const collapsible = /[^\P{White_Space}\u{00A0}]/u

  function textOffset(rootElement, node) {


    // walk the nodes up to the target node 
    // compute those lengths
    // I think this should be feasible with one call to treeTraverse
    // (not doing pre-work with treeFoldr) but I will start this way

    let pruned = pruneDown(rootElement, node)
    let finalChildren
    function procWrap(node, children, nodes) {

      let result = process(node, children, nodes)
      finalChildren = children;

      return result //[process(f,children), children]
    }

    const res = treeTraverse(procWrap, pruned)
    // console.debug('res',res,res.length)
    // console.debug(finalChildren.at(-1))
    // console.debug(res.slice(0, -node.textContent.length))
    // return res
    return res.slice(0, -node.textContent.length)
    // console.debug(finalChildren, node.textContent, nodeOffset)
    // return res.slice(0, -finalChildren.at(-1).length)
    // We don't need final children any more

  }

  // side note to join the billions of other side notes,
  // I don't know if treeTraverse can be used to 'filter'
  // with the way I have it now‚ÄîI think I need to revisit
  // traversables in my notes. Brush up on the knowledge.
  // I believe it should be doable. Like implementing
  // 'filter' in terms of 'map', in fact that's about the
  // approach I would use. treeTraverse doesn't expose
  // how it preserves tree structure. But I think it can
  // be done? going for a simpler approach now 

  // a state machine expressed in functional programming, you (would) love 2 see it


  // hf.addEventListener('beforeinput', (e) => console.log('hf pre-input', e))
  // hf.addEventListener('input', (e) => console.log('hf input', e))

  // caret offset from a root element to a child element - or just node in general?
  // yeah, see now, this is a recursive function. Where the base case is the root.
  // we could operate on nodes in general, compute offsets climbing up to the top.
  function elementOffset(root, element, initial=0) {

    if (!root.contains(element)) {
      // Semantic use of undefined, rather than throw an error
      return undefined;
    }

    let elems = treeFoldr(
      // clonc( x => x.contains(element),
      clonc( x => x === element,
        select(x => x.nodeType === Node.ELEMENT_NODE)), [], [], hf)

    let next = element;
    let offsetAccum = initial
    while (next !== root) {
      const { offsetLeft: x, offsetTop: y } = next
      let offset = 0;
      ({ offsetNode: next, offset } = document.caretPositionFromPoint(x, y))
      offsetAccum += offset;
    }
    return offsetAccum
  }

  function htmlElementFun(editor, node, offset) {

    let hte = treeFoldr(cat, [], editor).filter(n => n.nodeType === Node.ELEMENT_NODE);
    
      
  }
  
  const NBSP = '\u{00A0}' 
  // compared to \u{0020} which is a normal space ' '. we want 'whitespace' to exclude this. Then we don't need to
  // be concerned with trying to map innerHTML representations to text nodes.
  // another way to compute would be to compute lengths recursively, using innerText, adding it back to the whole.
  // Then, defined recursively, an element e has "textual space" that is e.innerText.length - (children elem lengths).
  // text nodes are 0 because they do not have innerText. That will be a nice, elegant way to compute html-awareness
  // for lengths! oooh Im into this now. would like to avoid regexp processing, because how many other characters should
  // I be handling, exactly? innerText already does the work I need, so I'd like to lean on that if I can

  // I'd love to use 'innerText' to compute the offset. I think that is more useful for going the other direction,
  // from a Doc-internal offset into the DOM selection, because then I can do the offset computation (which is 
  // kinda like an integral in a way) to compute.
  // yeah, weird, but I guess an "offset" is an expression of area. Of some dimension. And going between node,offset
  // to linear offset is swapping between 2d and 1d space. Like when you have a fixed-width grid you can compute
  // x,y coords from a single offset ( x,y = (n % width, floor(n / width)) ). The alternate computation is to
  // repeatedly add widths until adding one more goes beyond n, the amount of widths you added is y. then subtract
  // that amount from n to get x. For a variable width "grid" we have to use this second method.
  // The multiplcation/division method only works if we know the area function (so if it were e.g a triangular "grid"
  // we could still use a method derived from the derivative of the area to take advantage of multiplication.)
  // fun! math parallels.
  function getOffset(editor, node, offset) {
    let preserve = new WeakMap()
    let textNodes = treeFoldr(cat, [], editor)    // flatten
      .filter(n=>n.nodeType === Node.TEXT_NODE)   // just text
      .map(e => { 
        // console.debug(e)
        if ('innerHTML' in e && /&nbsp;/.test(e.innerHTML)) {
          preserve.set(e, "ha"); 
        }
        return e;
      })  // cheeky.
	    .filter(n=>!(/^\s*$/.test(n.textContent)))  // contentful text
    
    // though losing all information about the spaces, its not essential for learning offsets
    // we also don't yet handle line breaks between block elements, or collapsing spaces between
    // adjacent inlines

    let texts = textNodes.map(n => n.textContent)
      .map(s => s.replaceAll(/\s+/g, ' '))
    
    // console.debug(textNodes)
    // console.debug(texts)
    return texts.slice(0, textNodes.indexOf(node)).reduce((p,c) => p + c.length, 0) + offset

  }

  function _getOffset(editor, node, offset) {

    let fragment = new DocumentFragment();

    let flatDoc = treeFoldr(cat, [], editor).splice(1)  // cutout editor
    let nodeIndex = flatDoc.indexOf(node) // === treeFoldr(clonc(st, cat, []), [], hf) // Could further generalize the pattern, maybe instead of constantly Cat we start assuming that we. will be producing a list. then any list consuming func works. or really this is just defining it as a Monoid/Foldable

    let flatRange = flatDoc.slice(0, nodeIndex)
    console.log(flatRange)

    let blockOffset = flatRange.filter(n => n.nodeType === Node.ELEMENT_NODE) // roughly width*y if this where a grid
      .reduce((acc, cur) => cur.innerText.length + acc, 0)  
      // this will correctly count the blocks up to the ancestor of `node`, after which we need to compute adjustments, or stop and switch method
      // unfortunately the margin is all the wrapping margin. we might have to preserve just 'visited' nodes. this could be another fold.
      // if I could slice off the innerText that occurs *after* the node, recursively-aware... hm

    return blockOffset
  }

  function __getOffset(editor, node, offset) {
    // let textOffset = textOffset(editor, node)

    return treeFoldr(clonc(x => x === target))
    // strat - 
    // compute treeFolddr(cat, [], <above result> ), trim off. er. sum lengths? that kinda circles us back to original though?

    // return textOffset(editor, node) - 1 + offset;
  }

  const MARGINAL = {
    'p': 2, 'h1': 2, 'h2': 2, 'h3': 2,
    'br': 1,
  }



  function quash(text) {
    const breakingWhitespace = /[^\P{White_Space}\u{00A0}]/u
    return adjacentWhitespace.test(text)
  }

  // return the nodes of the tree that occur between root and target, inclusive, preserving structure
  function pruneDown(root, target) {
    // console.log(treeFoldr(_clonc( x => x === target, treeTraverseClone(), []), [], root)[0])
    // console.log(treeFoldr(clonc( x => x === target, treeTraverseClone(), []), [], root)[0])

    return treeFoldr(_clonc( x => x === target, treeTraverseClone(), []), [], root)[0]
    // return treeFoldr(clonc( x => x === target, treeTraverseClone(), []), [], root)[0]
  }

  function _textOffset(root, node) {
    return pruneDown(root, node).innerText.length
  }

  function _clonc(predicate, f, base) {
    
    return function ( n, prev ) {
      if (predicate(n)) {
        // return base
        // return x => f(x, base)
        return f(n, base)
      }
      return f(n, prev)
    }
  }


  // returns a function that attaches children to a tree unless the tree is the
  // searchNode, which just hands back the search node (resetting, in a sense, the tree)
  // apply f until hitting search node, which treats it like a base case
  function clonc(predicate, f, base) {
    
    return function ( n, prev ) {
      if (predicate(n)) {
        return x => f(x, n)
        // return f(n, base)
      }
      return f(n, prev)
    }
  }
  function cloncExclusive(predicate, f, base) { // like clonk but the 'reset' case doesn't submit n
    
    return function ( n, prev ) {
      if (predicate(n)) {
        return base
      }
      return f(n, prev)
    }
  }

  function sponk(n, prev) {
    if (prev.parentElem === n) {
      // return [n., prev]
    }
  }

  function treeTraverseClone(tMap = x => x) {  //default just clones the tree. okay can't think right now how to approach creating a structure-preserving tree map with a fold-right. I Think it should be do-able
    const parentMap = new WeakMap()

    function _treeID(node, previous) {
        // b/c of visit order, the children of the node make up the prefix to the list.
        // so we don't have to do anything else to preserve the structure other than filter for them
        // we have the following invariant: if i < j then nodes[i] appears before nodes[j] in the document

      const clone = node.cloneNode()
      parentMap.set(clone, node.parentElement)
      // const numChildren = previous.filter( p => p.parentElem === node).length
      // previous.slice(0, numChildren)
        // .forEach(n => clone.appendChild(n) )

      // a partition sort of function
      const [ kids, siblings ] = previous.reduce( ([ c, s ], n) => ( parentMap.get(n) === node ? [ [...c,n], s ] : [ c, [...s,n] ] ), [[],[]] ) // has functional programming gone TOO FARR? some would say: not nearly enough!

      kids.forEach(n => clone.appendChild(n))

      return [ clone, ...siblings ]
    }
    return _treeID
  }



  function processBlockChildren() {
    const breakingWhitespace = /[^\P{White_Space}\u{00A0}]/u
    if (node.nodeType === Node.COMMENT_NODE || []) {}

  }

  // yeah I know I know. Im feeling lazy at the moment
  const blockNodes = /^(p(re)?|h[1-6])$/i
  const blockSet = new Set(
    ["p", "h1", "h2", "h3", "div", "pre", "editor-hf"]
  )
  function process(node, children, childrenNodes) {

    if (node.nodeType === Node.COMMENT_NODE) {
      return ""
    }
    if (!node.hasChildNodes()) {
      // "" for childless elements, text for text nodes
      return node.textContent
    }

    const oneOrMoreWhitespace = /[^\P{White_Space}\u{00A0}]+/u

    function zip(l1, l2, f=(a,b)=>[a,b]) {
      const res = []
      for (let i = 0; i < l1.length && i < l2.length; i++) {
        res.push(f(l1[i], l2[i]))
      }
      return res
    }
    // here is where we have room to improve. We want to focus on converting
    // from browser representation to internal document. Right now this
    // relies on expectations about browser behavior or even the kinds of HTML
    // we'll munch on. Might be better served parsing the raw for internal use
    // so it's independent. That and we don't always need to compute selection
    // lengths, it's relevant for user operations when something is selected
    // yes but for many cases its not. We could for example re-build the document
    // internally on a cut or paste rather than try to mirror actions. 
    // Im rambling, I would like to stick to using the browser as a controller
    // and not the source of truth.
    function betwixt([[ c1Text, c1Node ], [ c2Text, c2Node ]]) {
      if (allWhiteSpace(c1Text)) {
        return "";
      }
        
      // Browser renders two line breaks for paragraphs
      // But funny note about differences between copying text, and *innerText*.
      // innerText renders spaces after each heading. so, I think I may stick to that.
      // if (c2Node?.tagName === 'P') {
      //   return "\n\n"
      // } else if (blockNodes.test(c1Node?.tagName)) {
      //   // Not all elements punch in the extra line break. Headings for example.
      //   return "\n";
      // }

      if (blockNodes.test(c1Node?.tagName)) {
        // innerText shows block elements with two spaces. Probably should test the space "between" block elements,
        // which I think would entail testing c2 and not c1. Or, maybe it doesn't matter since it gets cut?
        // ehhhh I need to break this up into an abstraction to finesse the details with ease (ironic, I suppose)
        // In this case the counting is equivalent, but notionally I'm not operating in a "between" sense even
        // (rather an "after" sense) though that's the context this function, ostensibly, operates under
        return "\n\n";
      }
      if (oneOrMoreWhitespace.test(c1Text.slice(-1)) || oneOrMoreWhitespace.test(c2Text.slice(0,1))) {
        return " "
      }
      return ""
    }
    function allWhiteSpace(string) {
      
      // string consists of all whitespace that aren't &nbsp;
      // this doesn't work for new lines
      return /^[^\P{White_Space}\u{00A0}]*$/u.test(string)
    }

    function collapseInternalBreaking(string) {
      return string.replaceAll(/[^\P{White_Space}\u{00A0}]+/gu,   ' ')
    }
    function trimLeading(string) {
      return string.replace(/^[^\P{White_Space}\u{00A0}]+/u, '')
    }
    function trimTrailing(string) {
      return string.replace(/[^\P{White_Space}\u{00A0}]+$/u,  '')
    }

    // can abstract the "process by type" (context-wise) pattern to 
    // parameterize the action it performs based on type. the 
    // interface picks which functions to use and we supply functions 
    // for each context.

    // The zip is "eager", it will fill in undefineds for remaining resources
    let adjacent = zip(children, childrenNodes)

    let paddingBetween = zip([["", undefined], ...adjacent], adjacent).map(betwixt)

    let collapsed = children.map(collapseInternalBreaking)
      .map((s,i) => i > 0 ? trimLeading(s) : s)
      .map((s,i) => i < children.length-1 ? trimTrailing(s) : s)

    let contextRender = zip(paddingBetween, collapsed, (s1, s2) => `${s1}${s2}`)

    let textRender = contextRender.join('')

    return textRender;

  }

  // Using process, we could offload work to sub functions.
  // an idea I like is returning context-functions, like
  // a state machine, so at each step it returns a function
  // that processes with the state. Like it would produce a
  // list and stepping through the list transitions to different
  // processing states, based on the functions that are returned.
  // would not actually need to be a statemachine.
  // a very powerful concept here is closures, because we can also
  // manage some state in the function itself, and I in fact make
  // use of that in treeTraverse (it captures tree in the closure
  // but variations like the treeTraverseClone capture the parent
  // information). In treeTraverse I also capture parent information
  // by way of passing the original data as the 'result', then
  // callbacks can include the information. Same principle but
  // implicitly handled


  // ex:
  // treeTraverse( (n, c) => n.hasChildNodes() ? `${n.tagName}:[${c}],` : `${n.textContent}`, <ROOT>)
  function treeTraverse(f, tree) {
    // tree traverse folds over the tree by applying functions that do an
    // in order traversal. It is built on using treeFoldr, but the difference
    // is the input function operates on the tree and its children that have
    // been recursively operated on.
    // treeFoldr only considers the tree and the record of processing the 
    // children recursively at that point in time. Semantically it's more like
    // traversing over a list.
    // Another way to imagine the difference is treeTraverse maps the recursion
    // onto its children, before applying the function to the parent and the
    // result of the map. A nice bonus is context from processing the right-er
    // elements of the tree is passed to the left-er parts of the tree because
    // its build on treeFoldr. In fact it is this bonus feature that enables
    // this to work at all.

    // const parentMap = new WeakMap()

    // function unwrapSnd( pairs ) {
    //   return pairs.map( ([_, x]) => x )
    // }

    function unzip( pairs ) {
      return pairs.reduce( ([accFst, accSnd], [fst, snd]) => [[...accFst, fst], [...accSnd, snd]], [[],[]])
    }

    function _combine(node, prev) {

      let numChildren = prev.reduce( (acc, [n,_]) => acc + (n.parentElement === node ? 1 : 0), 0 )
      let [childNodes, children] = unzip(prev.slice(0, numChildren))
      // callback is handed the original nodes too
      return [ [node, f(node, children, childNodes)], ...prev.slice(numChildren) ]

    }

    // could do the folding here, but I'm yielding the function to compose it
    // return _combine
    // or.
    return unzip(_treeFoldr(_combine, [], tree))[1][0]
    // return unzip(_treeFoldr(_combine, [], tree))

  }

  // e.innerText.length === treeFoldr(length, 0, e)

  let _hf_length = treeFoldr(length, 0, hf) // broken since a change made a time ago
  let _hf__length = treeFoldr(_length, 0, hf)
  let _hf_nodes = treeFoldr(cat, [], hf)
  let _length_check = _hf_nodes.map(n => [n, length(n), 'innerText' in n ? n.innerText.length : 0])
  // let _hf_margins = treeFoldr((n, [p=0, ...ps]) => [length(n, p), p, ...ps], [])
  let _hf_len_margins = treeFoldr((n, prev) => [length(n, prev[0]), ...prev], [], hf) // this is basically cat! but also a map! catmap!
  // ^ not actually margins oop

  let _hf_margins_fold = treeFold(lengthTreeFold, 0, hf)
  let _hf_margins_rec = margins(hf)
  let _hf_margins = treeFoldr(cat, [], hf).map(t => treeFold(lengthTreeFold, 0, t))
                      //  treeFoldr((n,p) => cat(treeFold(lengthTreeFold, 0, n), p), [], hf)  // its equivalent Im pretty sure
  let _hf_margins_check = _hf_nodes.map(n => [n, margins(n), treeFold(lengthTreeFold, 0, n)])
                                    .filter(([_, n, __]) => n !== 0)
  // almost...
  // _hf_margins_check.reduce((n,p) => n+p, 0)  === 1417
  // 100 more than _hf_length
  // the outermost should wrap with 0 extra characters, I wonder where they're coming from. Does the outer context
  // somehow include more characters from innerText?

  // more checks
  let cns = [...hf.childNodes]
    .filter(n=>n.nodeType === Node.ELEMENT_NODE)
    .map(e=>e.innerText)
    .reduce((acc,cur)=>cur.length + acc, 0)
  // ~1289 which is closer to the margin's I was expecting (1317 - 1289 = 28)
  // Off by 80, which is nice and round
  // couldn't be some weird code point/code unit shenanigans could it
  // ...could it

  // let all_children = []

  // I worked it out
  // Every block element carries an implicit +1 to the marginal addition of the parent even if it doesn't directly 
  // contribute anything
  // Two of the paragraphs render empty text. But they still get newlines. so I can work out the 28 difference as -
  let justcns = [...hf.childNodes].filter(n=>n.nodeType === Node.ELEMENT_NODE)
  // note that Im not reducing to innertext, which implicitly ignores any child element that has no rendered text (e.g a paragraph composed of raw whitespace that arent nbsp). That was part
  // of the confusion albeit unnoticed. 
  // But the parent renders a newline for block elements, *even ones that don't have any height*
  // ... !!! which tells me I should filter them out! if a paragraph is entered by a user for spacing text it has to have
  //    some thing within it. looking at what content-editable does, apparently inserts a <br>, wrapped in a paragraph..
  //    I guess in my computation a <br> should count as a leaf with margin 1. good to know! actually, it works out fine without
  //    special handling because the <p> should report the correct innerText. Looking at it, and it does, it reports a "\n". Nice
  // TAKEAWAY - PREPROCESS by filtering out "native" html elements with empty text. might revisit in the future if we add semantics
  //    to 'empty' content. could also shove in line breaks so it renders.

  let mgn = (justcns.length - 1   // subtract one because linebreaks are only rendered *between* block elements, not after the last one
    - 2)                          // surprise! subtract another two. There are 2 empty <p> tags which contribute nothing to the sum for the child elements, they get overlooked in the margin computation. This adjustment accounts for that. Otherwise we'd be over-counting the margin.
    * 2                           // the browser copies over a bonus linebreak between block elements
      // we would not make the adjustment for empty <p> if they had even one character rendered, because that would by nature be counted in the 'lengths'.
      // in a normal circumstance we could compute margin by summing up innerText from direct children and subtracting from the total
      // and equivalently compute by summing up the padding linebreaks, which we know are two per adjacent pair of block elements, of which directChildren.length - 1 exist
      // since the adjustment is a little unnatural it makes senes to me that we filter them out as part of pre-processing.
      // Okay! it only took all night to identify the relationship between child elements, margins of innertext,
      // yeah! okay we're onto *something*
      // helped by the fact that... innertext exists at all. Holy cow.
      // Im ~70% confident I could have found a way to work out 'innerText' from just textContent given I finally realized how
      // to identify &nbsp; (its \u{00A0}, so we can filter out \other\ whitespace). But it's complicated becaused then it's on us
      // to compute space squashing.
      // I might even have to do that anyway! A span embedded in a p, or two adjacent span, if the boundary characters are spaces...
      // will one have innerText with the space and the other not? if this isnt the case then Im kinda fuckled still, but I could
      // also just pre-process that I Think.
      // okay - thankfully the <p>chars <span> note the spaces..</span></p> case is fine, the span innertext negates the space so
      // the <p> computes the correct margin. Adjacent spans though - the margin might be *negative*
        // :sob: merciful web working group
        // it works the exact way I needed
        // the rule seems to be: collapse spaces at the left of a span. Collapse to a single space at the right.
        // this rule elegantly works for any nonsense case where extraneous spaces pad in each span
        // wondering though, what if no spaces pad the right side of the left span, but we have spaces on the left of the right
        // span? <s>ABRUPT</s><s> ...golly</s>
        // by the rule, it should render ABRUPT...golly
        // lets see..
        // ha! wow they are kind to me tonight. This is my reward for faithfulness.
        // the kind folks who made firefox at least seem to have a rule for consistency.
        // If a space is rendered between inline elements, or between parent and inline 
        // (which I supposed amounts to a textNode and an inline element, with the text
        // node having at least one rendered character) then it will report that one of
        // the two has the boundary space, even if it collapses the spaces down.
        // this is convenient and basically the way I need it to work 

  // nested header blocks would exhibit the same marginal behaviours I believe

  function margins(node) {
    if (! ('innerText' in node) ) {
      return 0
    }
    return node.innerText.length - ([...node.childNodes].reduce( (acc,cur) => margins(cur) + acc, 0))
  }

  function length(node, previous = 0) {
    
    if (!('innerText' in node)) { // comment or text node, e.g
    // if (node.nodeType === Node.TEXT_NODE) {
      // I know, weird, right? I was thinking, maybe return previous, then it's threaded through, which I think might yield what we want
      return 0;
    }

    return node.innerText.length - previous
  }

  function _length(node, previous = 0) {
    if (!('innerText' in node)) { // comment or text node, e.g
    // if (node.nodeType === Node.TEXT_NODE) {
      return previous; // nah, I dont think so
    }
    return node.innerText.length - previous
  }

  function scoop(node, childs) {
    return [{n:node}, childs]
  }
  function cat(node, childs) {
    return [node, ...childs]
  }
  function cannat(node, childs) {
    return [node, childs]
  }
  function select(predicate) {
    return (node, childs) => {
      if (predicate(node)) {
        return [node, ...childs]
      }
      return childs
    }   
  }

  // function fixText(node, childs) {
  //   if (node.childNodes.length === 0) {
  //     node.replaceAll()
  //   }
  //   return node
  // }

  // wonder if the 'base' case should be to return the base?
  // in a more general treeFoldr I'd say yes, it gives the 
  // users of the function a bit more control over what
  // happens at the end, like they don't have to be Aware of
  // handling the base differently. as I think I'll have to
  // do with this implementation.
  // maybe if this wasn't explicitly computing a function application.
  // Ha! I don't need your fancy web APIS! https://developer.mozilla.org/en-US/docs/Web/API/Document/createTreeWalker
  // (I'm kidding)
  // should treeFoldr implicitly 'cat'? since combining operations are treated as if it was handed a list anyway?
  // then clients can reuse any function they'd use in reduceRight. Or the base case should be a function producing thing too.
  // in fact yeah we got away from the function-producing mechanism some how
  function treeFoldr(f, base, tree) {
    // console.debug('treefoldr', tree, tree.childNodes)

    if (tree.childNodes.length === 0) {
      // console.log("LEAF", tree, base)
      return f(tree, base)
    } 

    const listapply = (treeList) => {
      return treeList.reduceRight( (res, item) => treeFoldr(f, res, item), base )
    }

    // const apply = (func, arg) => {
    //   console.debug("apply", arg, func)
    //   return x => treeFoldr(f, func(arg), x)
    // }
    const kiddos = [...tree.childNodes]
    // console.debug('Kiddos:', kiddos)

    // return f(tree, kiddos.reduce(apply, x => f(x, base)))
    return f(tree, listapply(kiddos))
  }

  function treeFoldrPost(f, base, tree) {
    if (tree.childNodes.length === 0) { // leaf
      return base
    }
    
  }

  // compare/contrast with the above, the base case handling. I think it's awkward since we combine foldr with
  // with the tree foldr, but they *each handle base differently*
  // like, the reduceRight doesn't use f(tree, base)! it spits back 'base'! hm! well, that makes sense
  // in a way because that 'base' never revers to a leaf node, it refers to the computed result of the
  // next right most sibling. Gets me thinking.
  // can I make a visualization for this? like a node-line graph svg that gets colored in as the computation
  // occurs
  function _treeFoldr(f, base, tree) {

    if (tree.childNodes.length === 0) {
      return base
    } 

    const listapply = (treeList) => {
      return treeList.reduceRight( (res, item) => treeFoldr(f, res, item), base )
      // return treeList.reduceRight( (res, item) => _treeFoldr(f, res, item), base )
    }
    return f(tree, listapply([...tree.childNodes]))
  }

  function lengthTreeFold(node, children) {
    if (node.childNodes.length === 0) {
      // I could remove this check by specifying 0 as the base value,
      // in liew of node.innerText.length, as node would not have
      // an innerText in this case. As much as that would make me smile
      // we didn't really get node in a form that's easy to check for 
      // that without an unfun comparison check anyway, unless I abstracted
      // out to arbitrary trees and had like an interface function that knew
      // details. Sigh
      return 0;
    }
    // foldl, fold *left*
    // subtracts the sum of the recursive result from the innerText length reported by the parent, to see the marginal additions
    // I think - here's a thought. When a component renders spaces, and its nested component does too, and it's inline,
    // or maybe even adjacent‚Äîthe parent view is that they collapse to 1 space. But each individually would report 0 spaces.
    // e.x <div><p>Hi </p><p> there</p></div>
    // div would report 2 + 1 + 5, but p:first-child would report 2 and p:last-child would report 5!
    // we lose one
    // so in OUR example we are somehow losing 108? Im dubious

    return children.reduce((accum, current) => accum - current, node.innerText.length)
  }

  // fold the tree without flattening it
  function treeFold(f, base, tree) {
    if (tree.childNodes.length === 0) {
      return f(tree, base)
    }
    // let processedChildren = [...tree.childNodes]
    //   .map()
    // possibly, could reduce the list in this func too, but 'f' can take that responsibility. A bit of flexibility. So 'f' operates on tree and a list
    return f(tree, [...tree.childNodes].map(subTree => treeFold(f, base, subTree)))
  }
  // gosh, it's still so similar to treeFoldr. Isnt there a way to define treeFoldr in terms of treeFold? 
  // from a functional perspective? I seem to remember that. It seems that crucial difference is treeFold
  // takes a function that operates on tree, and a list of result type. It traverses the tree pre-order.
  // treeFoldr "flattens" the tree to a list, and performs the operation with right-associativity
  // I think-- yes. This is a salient observation. treeFoldr is much more like foldr on a list.
  // In fact I believe it is just straight equivalent to first producing a pre order traversal then applying
  // foldr. It's more sophisticated to wrap those two steps into one function on trees, which is what I
  // skipped right to since that's what I wanted to produce for hf. But a typical fold on a tree obeys
  // more familiar tree semantics.
  // Another way to view the difference is the way that the fold is recursively called. In treeFold it's
  // mapped over the children trees, and in tree foldr it is still a kind of map, but the 'base' becomes the
  // next-right tree, plumbing the computation through the leaves. Ironically the right associativity makes
  // it a post-order traversal (in the imperative sense, lazy eval sense maybe it makes no difference) since
  // the bottom-"right" most leaf is the first one seen by the computation, but when the plumbing function is 
  // 'collapsed' at the end it becomes more like a list traversal and the evaluation proceeds as a pre-order.
  // 
  // visualized
  /*
  (* is a leaf)
      1
    2   5
   3 4 6 7
   * * * *
  tree fold 
  f(1, [f(2, [f(3, []), f(4, [])]), f(5, [f(6,[]), f(7, [])])])

  tree foldr
  f(1, f(2, f(3, f(4, f(5, f(6, f(7, [])))))))

  note how the base case only appears once in foldr vs for every leaf in fold


  ready for something cool and sexy?
  treeFold(cat, [], hf).flat(h) === treeFoldr(cat, [], hf)
    where h is the height of the tree (might need a +1 there)

  
  */

  
  console.log("!", treeTraverse(process, hf).trim() === hf.innerText, "!")

</script>